{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829fd29d-6e26-4a44-b004-b80f70e41b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting spark.hadoop.yarn.resourcemanager.principal to francesca.restante\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Application Id:spark-064ba12a5c4142629def47ebe59414fe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = 7941aa3f-ab5a-4f05-ad01-aff2fadd8c9a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|              app_io|\n",
      "|business_intellig...|\n",
      "|            cashback|\n",
      "|           checkiban|\n",
      "|      data_engineers|\n",
      "|       data_products|\n",
      "|   data_products_dev|\n",
      "|     data_scientists|\n",
      "|       data_strategy|\n",
      "|             default|\n",
      "|      dl_anagrafiche|\n",
      "|       dl_tassonomie|\n",
      "|             dtd_bul|\n",
      "|         dtd_bul_dev|\n",
      "|             dtd_dev|\n",
      "|             dtd_fse|\n",
      "|         dtd_fse_dev|\n",
      "|           dtd_istat|\n",
      "|           dtd_pad26|\n",
      "|       dtd_pad26_dev|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cml.data_v1 as cmldata\n",
    "\n",
    "import configparser\n",
    "import uuid\n",
    "import os\n",
    "from typing import Dict\n",
    "from pyspark.sql.functions import to_date, col\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession, DataFrameWriter\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DateType, StringType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta, date\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import col, ceil, when\n",
    "import pandas as pd\n",
    "\n",
    "# Sample in-code customization of spark configurations\n",
    "#from pyspark import SparkContext\n",
    "#SparkContext.setSystemProperty('spark.executor.cores', '1')\n",
    "#SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "\n",
    "CONNECTION_NAME = \"pdnd-prod-dl-1\"\n",
    "conn = cmldata.get_connection(CONNECTION_NAME)\n",
    "spark = conn.get_spark_session()\n",
    "\n",
    "# Sample usage to run query through spark\n",
    "EXAMPLE_SQL_QUERY = \"show databases\"\n",
    "spark.sql(EXAMPLE_SQL_QUERY).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529397e0-bf24-4e5c-b3ac-72211a5ec523",
   "metadata": {},
   "outputs": [],
   "source": [
    "festivita = [\n",
    "    ('2023-01-01', 'Capodanno'),\n",
    "    ('2023-01-06', 'Epifania'),\n",
    "    ('2023-04-09', 'Pasqua'),\n",
    "    ('2023-04-10', 'Lunedì dell\\'Angelo'),\n",
    "    ('2023-04-25', 'Festa della Liberazione'),\n",
    "    ('2023-05-01', 'Festa dei Lavoratori'),\n",
    "    ('2023-06-02', 'Festa della Repubblica'),\n",
    "    ('2023-08-15', 'Ferragosto'),\n",
    "    ('2023-11-01', 'Tutti i Santi'),\n",
    "    ('2023-12-08', 'Immacolata Concezione'),\n",
    "    ('2023-12-25', 'Natale'),\n",
    "    ('2023-12-26', 'Santo Stefano'),\n",
    "\n",
    "    ('2024-01-01', 'Capodanno'),\n",
    "    ('2024-01-06', 'Epifania'), \n",
    "    ('2024-04-01', 'Lunedì dell\\'Angelo'),\n",
    "    ('2024-03-31', 'Pasqua'),\n",
    "    ('2024-04-25', 'Festa della Liberazione'),\n",
    "    ('2024-05-01', 'Festa dei Lavoratori'),\n",
    "    ('2024-06-02', 'Festa della Repubblica'),\n",
    "    ('2024-08-15', 'Ferragosto'),\n",
    "    ('2024-11-01', 'Tutti i Santi'),\n",
    "    ('2024-12-25', 'Natale'),\n",
    "    ('2024-12-26', 'Santo Stefano'),\n",
    "\n",
    "    ('2025-01-01', 'Capodanno'),\n",
    "    ('2025-01-06', 'Epifania'),\n",
    "    ('2025-04-20', 'Pasqua'),\n",
    "    ('2025-04-21', 'Lunedì dell\\'Angelo'),\n",
    "    ('2025-04-25', 'Festa della Liberazione'),\n",
    "    ('2025-05-01', 'Festa dei Lavoratori'),\n",
    "    ('2025-06-02', 'Festa della Repubblica'),\n",
    "    ('2025-08-15', 'Ferragosto'),\n",
    "    ('2025-11-01', 'Ognissanti'),\n",
    "    ('2025-12-08', 'Immacolata Concezione'),\n",
    "    ('2025-12-25', 'Natale'),\n",
    "    ('2025-12-26', 'Santo Stefano')\n",
    "]\n",
    "\n",
    "holiday_dates = {datetime.strptime(date, '%Y-%m-%d').date() for date, _ in festivita}\n",
    "#holiday_dates = set(map(lambda x: datetime.strptime(x[0], '%Y-%m-%d'), festivita))\n",
    "#holiday_dates_list = list(holiday_dates)\n",
    "\n",
    "festivita_df = spark.createDataFrame(festivita, [\"data\", \"descrizione\"])\n",
    "\n",
    "festivita_df = festivita_df.withColumn(\"data\", to_date(festivita_df[\"data\"], \"yyyy-MM-dd\"))\n",
    "\n",
    "festivita_df.createOrReplaceTempView(\"FestivitaView\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbad67ab-4778-477d-bf7a-1601643efac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datediff_workdays(start_date, end_date):\n",
    "    try:\n",
    "        if start_date is None or end_date is None:\n",
    "            return None\n",
    "\n",
    "        if end_date < start_date:\n",
    "            return 0\n",
    "\n",
    "        start_date_next_day = start_date.replace(hour=0, minute=0, second=0) + timedelta(days=1)\n",
    "\n",
    "        total_days = (end_date - start_date_next_day).days\n",
    "\n",
    "        days_list = [start_date_next_day + timedelta(days=i) for i in range(total_days + 1)]\n",
    "\n",
    "        working_days = [d for d in days_list if d.weekday() < 5 and d.date() not in holiday_dates]\n",
    "\n",
    "        total_working_days = len(working_days)\n",
    "\n",
    "        return total_working_days\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "datediff_workdays_udf = udf(datediff_workdays, IntegerType())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8ae29-dbf1-405b-81cc-b68992371f27",
   "metadata": {},
   "source": [
    "### Prova su date dal db"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24019b90-e993-4b69-9afe-70744f98e4b5",
   "metadata": {},
   "source": [
    "\n",
    "df_con_diff = df.withColumn(\n",
    "    \"differenza_giorni\",\n",
    "    datediff_workdays_udf(\n",
    "        to_timestamp(F.lit(\"2025-06-26 06:14:00.000\")),\n",
    "        to_timestamp(F.lit(\"2025-07-01 05:14:00.000\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "df_con_diff.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "580ad138-3cdb-4175-bf5f-f30564ea8399",
   "metadata": {},
   "source": [
    "prova_differenza_giorni = datediff_workdays_udf(\"2025-06-26 6:14\", \"2025-07-01 9:15\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c69aa6d-0355-4de3-9404-7f3cedaad6f9",
   "metadata": {},
   "source": [
    "print(prova_differenza_giorni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980eb8bb-b3ab-4c5c-9690-dbed0c501d42",
   "metadata": {},
   "source": [
    "### Query di estrazione\n",
    "##### modifiche apportate:\n",
    "##### - esclusione degli iun presenti in incident\n",
    "##### - esclusione di tutte le postalizzazioni che hanno almeno un evento di recapito valorizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfc31ec-8e9e-4b55-8e65-9f4173e979ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        gpa.senderpaid,\n",
    "        gpa.requestID, \n",
    "        gpa.requesttimestamp, \n",
    "        gpa.prodotto,\n",
    "        gpa.geokey,\n",
    "        CASE \n",
    "            WHEN gpa.affido_consolidatore_data IS NULL \n",
    "            THEN gpa.requesttimestamp \n",
    "            ELSE gpa.affido_consolidatore_data \n",
    "        END AS affido_consolidatore_data,\n",
    "        gpa.stampa_imbustamento_con080_data,\n",
    "        gpa.materialita_pronta_CON09A_data,\n",
    "        gpa.affido_recapitista_con016_data,\n",
    "        gpa.accettazione_recapitista_con018_data\n",
    "    FROM \n",
    "        send.gold_postalizzazione_analytics AS gpa\n",
    "    JOIN \n",
    "        send.gold_notification_analytics AS gna\n",
    "        ON gpa.iun = gna.iun\n",
    "    WHERE \n",
    "        gpa.accettazione_recapitista_con018_data IS NULL\n",
    "        AND gpa.scarto_consolidatore_stato IS NULL\n",
    "        AND gpa.pcretry_rank = 1\n",
    "        AND gpa.tentativo_recapito_stato IS NULL \n",
    "        AND gpa.messaingiacenza_recapito_stato IS NULL \n",
    "        AND gpa.certificazione_recapito_stato IS NULL \n",
    "        AND gpa.fine_recapito_stato IS NULL \n",
    "        AND gpa.demat_23l_ar_stato IS NULL\n",
    "        AND gpa.demat_plico_stato IS NULL\n",
    "        AND gpa.iun NOT IN (\n",
    "            SELECT iun \n",
    "            FROM send.silver_incident_iun\n",
    "        )\n",
    "        AND gna.actual_status <> 'CANCELLED'\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41e9e513-6d93-4659-a6d2-bd67fa78d0cd",
   "metadata": {},
   "source": [
    "df_start.select(\n",
    "    F.col(\"affido_consolidatore_data\"),\n",
    "    F.current_timestamp(),\n",
    "    datediff_workdays_udf(F.col(\"affido_consolidatore_data\"), F.current_timestamp()).alias(\"diff_workdays\")\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "194e9b9a-4037-441f-8142-446c68b15d06",
   "metadata": {},
   "source": [
    "inserire nuovo cluster Pick-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5102f7-bff6-4861-89d3-9a5f4e85518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_start = df_start.withColumn(\"Cluster\",\n",
    "                                F.when(F.col(\"stampa_imbustamento_con080_data\").isNull() & \n",
    "                                           (datediff_workdays_udf(F.col(\"affido_consolidatore_data\"),F.current_timestamp()) > 2), \"Stampa Imbustamento\") \n",
    "                                 .when(F.col(\"materialita_pronta_CON09A_data\").isNull() & \n",
    "                                       (datediff_workdays_udf(F.col(\"stampa_imbustamento_con080_data\"),F.current_timestamp()) > 2), \"Materialita Pronta\")\n",
    "                                 .when(F.col(\"affido_recapitista_con016_data\").isNull() &\n",
    "                                       (datediff_workdays_udf(F.col(\"stampa_imbustamento_con080_data\"),F.current_timestamp()) > 2), \"Pick Up\")\n",
    "                                 .when(F.col(\"accettazione_recapitista_con018_data\").isNull() & \n",
    "                                       (datediff_workdays_udf(F.col(\"affido_recapitista_con016_data\"), F.current_timestamp()) > 1), \"Accettazione Recapitista\"))\n",
    "                                 \n",
    "df_start = df_start.filter(F.col(\"Cluster\").isNotNull())\n",
    "\n",
    "df_start = df_start.withColumn(\"Priority\", \n",
    "                                F.when(F.col(\"Cluster\") == \"Stampa Imbustamento\", 4)\n",
    "                                 .when(F.col(\"Cluster\") == \"Materialita Pronta\", 3)\n",
    "                                 .when(F.col(\"Cluster\") == \"Pick Up\", 2)\n",
    "                                 .when(F.col(\"Cluster\") == \"Accettazione Recapitista\", 1))\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cffbd2c-0e7f-4a07-b0fe-8d4ec2b2733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"requestID\").orderBy(\"Priority\")\n",
    "\n",
    "df_start_with_rank = df_start.withColumn(\"rank\", F.row_number().over(windowSpec))\n",
    "\n",
    "\n",
    "df_filtered = df_start_with_rank.filter(F.col(\"rank\") == 1).drop(\"rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8eec75-8c97-484a-b675-8c31d905e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.withColumn(\n",
    "    \"differenza_gg_lavorativi\",\n",
    "    F.when(\n",
    "        F.col(\"Cluster\") == \"Stampa Imbustamento\",\n",
    "        datediff_workdays_udf(F.col(\"affido_consolidatore_data\"), F.current_timestamp())\n",
    "    ).when(\n",
    "        F.col(\"Cluster\") == \"Materialita Pronta\",\n",
    "        datediff_workdays_udf(F.col(\"stampa_imbustamento_con080_data\"), F.current_timestamp())\n",
    "    ).when(\n",
    "        F.col(\"Cluster\") == \"Pick Up\",\n",
    "        datediff_workdays_udf(F.col(\"stampa_imbustamento_con080_data\"), F.current_timestamp())\n",
    "    ).when(\n",
    "        F.col(\"Cluster\") == \"Accettazione Recapitista\",\n",
    "        datediff_workdays_udf(F.col(\"affido_recapitista_con016_data\"), F.current_timestamp())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28dada0d-9039-464d-8d64-e1eb5a614513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.withColumn(\n",
    "    \"gg_fuori_sla\",\n",
    "    F.when(\n",
    "        F.col(\"Cluster\") == \"Stampa Imbustamento\",\n",
    "        datediff_workdays_udf(F.col(\"affido_consolidatore_data\"), F.current_timestamp()) - 2 \n",
    "    ).when(\n",
    "        F.col(\"Cluster\") == \"Materialita Pronta\",\n",
    "        datediff_workdays_udf(F.col(\"stampa_imbustamento_con080_data\"), F.current_timestamp()) - 2 \n",
    "    ).when(\n",
    "        F.col(\"Cluster\") == \"Pick Up\",\n",
    "        datediff_workdays_udf(F.col(\"stampa_imbustamento_con080_data\"), F.current_timestamp()) - 2\n",
    "    ).when(\n",
    "        F.col(\"Cluster\") == \"Accettazione Recapitista\",\n",
    "        datediff_workdays_udf(F.col(\"affido_recapitista_con016_data\"), F.current_timestamp()) - 1 \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08037a3b-d9cf-4feb-9459-75f6d199642b",
   "metadata": {},
   "source": [
    "## Esportare il risultato in tabella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa14c135-f4fa-4903-8142-4d302f927574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.createOrReplaceTempView(\"DF_OUTPUT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527aec53-e010-4f38-b841-aee0df4f648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM DF_OUTPUT\"\"\").writeTo(\"send_dev.wi7_consolidatore\")\\\n",
    "                .using(\"iceberg\")\\\n",
    "                .tableProperty(\"format-version\",\"2\")\\\n",
    "                .tableProperty(\"engine.hive.enabled\",\"true\")\\\n",
    "                .createOrReplace()\n",
    "#print(datetime.now()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
